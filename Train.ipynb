{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.has_mps:\n",
    "    print(\"Congratulations, you have GPU support for PyTorch! \\U0001F389\")\n",
    "else:\n",
    "    print(\"Sorry, it looks like something isn't working right with PyTorch GPU support\")\n",
    "\n",
    "device = torch.device('mps' if torch.has_mps else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column_names = ['NE01_AHU7_RESET_POLL_TL', 'NE01_AHU7_HCV_POLL_TL', 'NE01_AHU7_HC_SWT_POLL_TL', 'NE01_AHU7_HC_RWT_POLL_TL', 'NE01_AHU7_MAD_FB_POLL_TL',\n",
    "                      'NE01_AHU7_HC_SAT_POLL_TL', 'NE01_AHU7_MAT_POLL_TL', 'NE01_AHU7_RAT_POLL_TL', 'NE01_AHU7_SF_SPD_POLL_TL', 'NE01_AHU7_EF_SPD_POLL_TL', 'NE01_AHU5_OAT_GV_POLL_TL']\n",
    "output_column_names = ['VAV4_1_RT_TL', 'VAV4_2_RT_TL', 'VAV4_3_RT_TL',\n",
    "                       'VAV4_4_RT_TL', 'VAV4_5_RT_TL', 'VAV4_6_RT_TL', 'VAV4_7_RT_TL']\n",
    "all_column_names = input_column_names + output_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('pulled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe, test_dataframe = train_test_split(dataframe, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe[all_column_names].to_csv('train_dataset.txt', index=False, header=False)\n",
    "test_dataframe[all_column_names].to_csv('test_dataset.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "train_path = 'train_dataset.txt'\n",
    "test_path = 'test_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path, test_path, tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "     \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator\n",
    "\n",
    "train_dataset, test_dataset, data_collator = load_dataset('train_dataset.txt', 'test_dataset.txt', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments,AutoModelWithLMHead\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained('gpt2').to(device)\n",
    "print(model.device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./gpt2-hvac',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_steps=400,\n",
    "    save_steps=800,\n",
    "    warmup_steps=500,\n",
    "    prediction_loss_only=True,\n",
    "    log_level='debug'\n",
    ")\n",
    "\n",
    "training_args.device\n",
    "\n",
    "print(training_args.device)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b03500ce55b291f8816d5441524bb5fc71203f9aa40c27b9c98ac0587038fe3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
